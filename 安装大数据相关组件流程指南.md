# Centos7.5基础配置

## 1.在hadoop101进行免密登录,分发到其他节点

```shell
1.
vim /etc/hosts
2.在节点hadoop101添加
172.24.228.158 hadoop101  //阿里云私有ip
172.24.198.155 hadoop102
172.24.228.159 hadoop103
3.将配置的免密登录分发到其他机器
scp /etc/hosts hadoop102:/etc/
scp /etc/hosts hadoop103:/etc/
4.在每个节点输入:
ssh-keygen -t rsa
2)在每个节点执行以下内容,并输入密码
ssh-copy-id hadoop101
ssh-copy-id hadoop102
ssh-copy-id hadoop103
```

## 2.JDK配置

```shell
1)解压JDK8的tar包
mkdir /opt/module
tar -zxvf jdk-8u144-linux-x64.tar.gz -C /opt/module
2)配置环境变量
	1.进入
    vim /etc/profile.d/my_env.sh
    2.添加
    export JAVA_HOME=/opt/module/jdk1.8.0_144
    export PATH=$PATH:$JAVA_HOME/bin
    3.分发环境变量配置
    scp /etc/hosts hadoop102:/etc/
    scp /etc/hosts hadoop103:/etc/
    4.分别到不同节点source一下将配置更新
    source /etc/profile
```

# Zookeeper安装

（1）上传压缩包到software文件夹，并进行解压

```
[root@hadoop101 module]# cd /opt/software/

[root@hadoop101 software]# tar -zxvf apache-zookeeper-3.5.7-bin.tar.gz  -C /opt/module/
```

（2）分发到各节点

```
[root@hadoop101 software]# cd /opt/module/

[root@hadoop101 module]# scp -r apache-zookeeper-3.5.7-bin/ hadoop102:/opt/module/

[root@hadoop101 module]# scp -r apache-zookeeper-3.5.7-bin/ hadoop103:/opt/module/
```

（2）在zookeeper目录创建zkData目录	

```
[root@hadoop101 module]# cd apache-zookeeper-3.5.7-bin/

[root@hadoop101 apache-zookeeper-3.5.7-bin]# mkdir zkData
```

（3）在zkData目录下创建myid文件,写上对应比编号1并保存

```
[root@hadoop101 apache-zookeeper-3.5.7-bin]# cd zkData/

[root@hadoop101 zkData]# vim myid

1
```

（5）分发zkData目录

```
[root@hadoop101 zkData]# cd ..

[root@hadoop101 apache-zookeeper-3.5.7-bin]# scp -r zkData/ hadoop102:/opt/module/apache-zookeeper-3.5.7-bin/

[root@hadoop101 apache-zookeeper-3.5.7-bin]# scp -r zkData/ hadoop103:/opt/module/apache-zookeeper-3.5.7-bin/
```

（6）配置zoo.cfg

```
[root@hadoop101 apache-zookeeper-3.5.7]# cd conf/

[root@hadoop101 conf]# mv zoo_sample.cfg zoo.cfg

[root@hadoop101 conf]# vim zoo.cfg 

修改数据存储路径

dataDir=/opt/module/apache-zookeeper-3.5.7-bin/zkData

在文件末尾处增加集群配置

server.1=hadoop101:2888:3888

server.2=hadoop102:2888:3888

server.3=hadoop103:2888:3888

分发zoo.cfg

[root@hadoop101 conf]# scp zoo.cfg hadoop102:/opt/module/apache-zookeeper-3.5.7-bin/conf/

[root@hadoop101 conf]# scp zoo.cfg hadoop103:/opt/module/apache-zookeeper-3.5.7-bin/conf/
```

（7）修改其余两台机器的myid,分别为2,3

```
[root@hadoop102 apache-zookeeper-3.5.7]# vim zkData/myid 

2
```

```
[root@hadoop103 apache-zookeeper-3.5.7]# vim zkData/myid 

3
```

（8）启动集群

```
[root@hadoop101 ~]# /opt/module/apache-zookeeper-3.5.7-bin/bin/zkServer.sh start

[root@hadoop102~]# /opt/module/apache-zookeeper-3.5.7-bin/bin/zkServer.sh start

[root@hadoop103 ~]# /opt/module/apache-zookeeper-3.5.7-bin/bin/zkServer.sh start

 
```



# Hadoop安装

## Hadoop3.1.3安装

```shell
1)在hadoop01节点上安装
tar -zxvf hadoop3.1.3 -C /opt/module
2)分发到其他节点
scp -r hadoop-3.1.3/ /hadoop102:/opt/module    //-r递归复制整个目录
scp -r hadoop-3.1.3/ /hadoop103:/opt/module
3)更改环境变量
    1.配置环境变量
    vim /etc/profile
    2.添加
    #HADOOP_Home
	export HADOOP_HOME=/opt/module/hadoop-3.1.3
	export PATH=$PATH:$HADOOP_HOME/bin
    3.分发环境变量配置
    scp /etc/profile hadoop102:/etc/
    scp /etc/profile hadoop103:/etc/
  	4.各个节点source一下使配置生效
  	source /etc/profile
  	
  	/opt/module/jdk1.8.0_144
```

配置集群

### 集群配置

集群部署规划

注意：NameNode和SecondaryNameNode不要安装在同一台服务器

注意：ResourceManager也很消耗内存，不要和NameNode、SecondaryNameNode配置在同一台机器上。

|      | hadoop102        | hadoop103                  | hadoop104                 |
| ---- | ---------------- | -------------------------- | ------------------------- |
| HDFS | NameNodeDataNode | DataNode                   | SecondaryNameNodeDataNode |
| YARN | NodeManager      | ResourceManagerNodeManager | NodeManager               |

2）配置集群

（1）核心配置文件

配置core-site.xml

```shell
[atguigu@hadoop102 .ssh]$ cd /opt/module/hadoop-3.1.3/etc/hadoop/

[atguigu@hadoop102 hadoop]$ vim core-site.xml
```

文件内容如下：

```
<configuration>
    <property>
        <name>fs.defaultFS</name>
        <value>hdfs://hadoop101:8020</value>
    </property>
    <property>
        <name>hadoop.tmp.dir</name>
        <value>/opt/module/hadoop-3.1.3/data</value>
    </property>
    <property>
        <name>hadoop.proxyuser.atguigu.hosts</name>
        <value>*</value>
    </property>
    <property>
        <name>hadoop.proxyuser.atguigu.groups</name>
        <value>*</value>
    </property>
    <property>
        <name>hadoop.http.staticuser.user</name>
        <value>atguigu</value>
    </property>
</configuration>
```

（2）HDFS配置文件

配置hdfs-site.xml

```shell
[atguigu@hadoop102 hadoop]$ vim hdfs-site.xml
```

文件内容如下：

```
<configuration>
    <property>
        <name>dfs.namenode.secondary.http-address</name>
        <value>hadoop103:9868</value>
    </property>
<!-- 指定HDFS副本的数量 -->
<property>
	<name>dfs.replication</name>
	<value>1</value>
</property>
</configuration>
```

（3）YARN配置文件

配置yarn-site.xml

```
[atguigu@hadoop102 hadoop]$ vim yarn-site.xml
```

文件内容如下：

```shell
<configuration>
    <property>
        <name>yarn.nodemanager.aux-services</name>
        <value>mapreduce_shuffle</value>
    </property>
    <property>
        <name>yarn.resourcemanager.hostname</name>
        <value>hadoop103</value>
    </property>
    <property>
        <name>yarn.nodemanager.env-whitelist</name>
        <value>JAVA_HOME,HADOOP_COMMON_HOME,HADOOP_HDFS_HOME,HADOOP_CONF_DIR,CLASSPATH_PREPEND_DISTCACHE,HADOOP_YARN_HOME,HADOOP_MAPRED_HOME</value>
    </property>
    <property>
        <name>yarn.scheduler.minimum-allocation-mb</name>
        <value>512</value>
    </property>
    <property>
        <name>yarn.scheduler.maximum-allocation-mb</name>
        <value>4096</value>
    </property>
    <property>
        <name>yarn.nodemanager.resource.memory-mb</name>
        <value>4096</value>
    </property>
    <property>
        <name>yarn.nodemanager.pmem-check-enabled</name>
        <value>false</value>
    </property>
    <property>
        <name>yarn.nodemanager.vmem-check-enabled</name>
        <value>false</value>
    </property>
</configuration>
```

（4）MapReduce配置文件

配置mapred-site.xml

```shell
[atguigu@hadoop102 hadoop]$ vim mapred-site.xml
```

文件内容如下：

```shell
<configuration>
    <property>
        <name>mapreduce.framework.name</name>
        <value>yarn</value>
    </property>
</configuration>
```

**3）在集群上分发配置好的Hadoop配置文件**

```
[atguigu@hadoop102 hadoop]$ xsync /opt/module/hadoop-3.1.3/etc/hadoop/
```

4）查看文件分发情况

```
[atguigu@hadoop103 hadoop]$cat /opt/module/hadoop-3.1.3/etc/hadoop/core-site.xml
```

### **群起**集群

1）配置workers

```
[atguigu@hadoop102 hadoop]$ vim /opt/module/hadoop-3.1.3/etc/hadoop/workers
```

在该文件中增加如下内容：

```
hadoop101
hadoop102
hadoop103
```

注意：该文件中添加的内容结尾不允许有空格，文件中不允许有空行。

同步所有节点配置文件

```
[atguigu@hadoop102 hadoop]$ xsync /opt/module/hadoop-3.1.3/etc
```

**2）启动集群**

1）**如果集群是第一次启动**，需要在hadoop101节点格式化NameNode（注意格式化之前，一定要先停止上次启动的所有namenode和datanode进程，然后再删除data和log数据）

```
[atguigu@hadoop102 hadoop-3.1.3]$ bin/hdfs namenode -format
```

（2）启动HDFS

```
[atguigu@hadoop102 hadoop-3.1.3]$ sbin/start-dfs.sh
```

（3）在配置了ResourceManager的节点（hadoop102）启动YARN

```
[atguigu@hadoop103 hadoop-3.1.3]$ sbin/start-yarn.sh
```

（4）Web端查看HDFS的Web页面：<http://hadoop101:9870/>

![1606616603632](C:\Users\monster\AppData\Local\Temp\1606616603632.png)



![1606616621244](C:\Users\monster\AppData\Local\Temp\1606616621244.png)

# Mysql安装

# Flume安装

## Flume安装部署

###  **安装地址**

（1） Flume官网地址：<http://flume.apache.org/>

（2）文档查看地址：<http://flume.apache.org/FlumeUserGuide.html>

（3）下载地址：http://archive.apache.org/dist/flume/

###  **安装部署**

（1）将apache-flume-1.9.0-bin.tar.gz上传到linux的/opt/software目录下

（2）解压apache-flume-1.9.0-bin.tar.gz到/opt/module/目录下

```
[atguigu@hadoop102 software]$ tar -zxf /opt/software/apache-flume-1.9.0-bin.tar.gz -C /opt/module/
```

（3）修改apache-flume-1.9.0-bin的名称为flume

```
[atguigu@hadoop102 module]$ mv /opt/module/apache-flume-1.9.0-bin /opt/module/flume
```

（4）将lib文件夹下的guava-11.0.2.jar删除以兼容Hadoop 3.1.3

```
rm /opt/module/flume/lib/guava-11.0.2.jar
```

（5）将flume/conf下的flume-env.sh.template文件修改为flume-env.sh，并配置flume-env.sh文件

```shell
[atguigu@hadoop102 conf]$ mv flume-env.sh.template flume-env.sh

[atguigu@hadoop102 conf]$ vi flume-env.sh

export JAVA_HOME=/opt/module/jdk1.8.0_212
```

